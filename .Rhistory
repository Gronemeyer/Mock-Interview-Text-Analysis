install.packages("ggplot2")
install.packages("wordcloud")
install.packages("SnowballC")
install.packages("gridExtra")
install.packages("textmineR")
library (tidytext)
library (SentimentAnalysis)
install.packages("SentimentAnalysis")
install.packages("dplyr")
install.packages("stringr")
install.packages("qdap")
install.packages("textdata")
install.packages("igraph")
install.packages("ggraph")
library (tm)
library (tidyr)
library (readr)
library (stringi)
library (RWeka)
library (ggplot2)
library (wordcloud)
library (SnowballC)
library (gridExtra)
library (textmineR)
library (tidytext)
library (SentimentAnalysis)
library (dplyr)
library (stringr)
library (tidytext)
library (qdap)
install.packages("qdapTools")
library (wordcloud)
library (SnowballC)
library (gridExtra)
library (textmineR)
library (tidytext)
library (SentimentAnalysis)
library (dplyr)
library (stringr)
library (tidytext)
library (qdap)
library (textdata)
library (igraph)
library (ggraph)
RAtidy <- tidy(NTcorpus)
RAtidy <- tidy(RAcorpus)
RAtdf <- tokenize_it(RAtidy)
tokenize_it <- function(file_corpus) {
#this function requires a tidy file corpus as input
tidy_corp <- file_corpus %>%
group_by(id) %>%
summarize(text) %>%
mutate(id = factor(id)) %>% #make sure to mutate the "id" column^
ungroup() #formats corpus for tidy analysis
tidy_text <- tidy_corp %>%
unnest_tokens(word, text) #creates tidy text tibble
file_corpus <- tidy_text
rm(tidy_corp)
return(file_corpus)
}
#
bigram_it <- function(file_corpus) {
#this function requires a tidy file corpus as input
cnt <- 1 #tidy up the id names
repeat{
file_corpus[["id"]][[cnt]] <- substr(file_corpus[["id"]][[cnt]], 1, 12) #substracts all parts of the char string and leaves 1-10
cnt <- cnt+1
if(cnt > length(file_corpus)){
break
}
}
tidy_corp <- file_corpus %>%
group_by(id) %>%
summarize(text) %>%
mutate(id = factor(id)) %>% #make sure to mutate the "id" column^
ungroup() #formats corpus for tidy analysis
tidy_text <- tidy_corp %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) #creates tidy text tibble
bigrams_seperated <- tidy_text %>%
separate(bigram, c("word1", "word2"), sep = " ")
bigrams_filtered <- bigrams_seperated %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
mystopwords <- tibble(word = c("name 1", "name 2", "uhm", "um", "uh", "00", "etc", "let's", "gotta", "adrian", "bn"))
bigrams_filtered <- bigrams_filtered %>%
filter(!word1 %in% mystopwords$word) %>%
filter(!word2 %in% mystopwords$word)
bigram_counts <- bigrams_filtered %>%
count(word1, word2, sort = TRUE)
file_corpus <- tidy_text
return(bigram_counts)
}
#
rem_stopwords <- function(x) {
data("stop_words") #calls stop_word data set into Global Environment
tidy_text <- x %>%
anti_join(stop_words) #removes stop_words found in tidy_text
#mystopwords <- tibble(word = c("pop", "forget", "library", "skip", "spelling", "technology", "clerical", "unintelligible", "inaudible", "fully", "pay", "money", "swim", "splitting", "mother", "illegal", "stealing", "feeling", "police", "words", "question", "name1", "name2", "uhm", "um", "uh", "00", "etc", "let's", "gotta", "adrian", "bn"))
#mystopwords <- tibble(word = c("bug", "bugs" ,"pop", "forget", "library", "skip", "spelling", "technology", "clerical", "unintelligible", "inaudible", "fully", "pay", "money", "swim", "splitting", "mother", "illegal", "stealing", "feeling", "police", "words", "question", "name1", "name2", "uhm", "um", "uh", "00", "etc", "let's", "gotta", "adrian", "bn"))
tidy_text <- x %>%
anti_join(mystopwords) #removes stop_words found in tidy_text
return(tidy_text)
}
#
tf_analysis <- function(file_corpus, sent_input, plotTF, plotTFidf){
cnt <- 1 #tidy up the id names
repeat{
file_corpus[["id"]][[cnt]] <- substr(file_corpus[["id"]][[cnt]], 1, 12) #substracts all parts of the char string and leaves 1-10
cnt <- cnt+1
if(cnt > 24){
break
}
}
IMPASD_freq <- file_corpus %>% mutate(id = factor(id)) %>%
unnest_tokens(word, text)
IMPASD_freq <- rem_stopwords(IMPASD_freq)
words <- IMPASD_freq %>% count (id, word, sort = TRUE) %>% group_by(id) %>% summarise(wordcount = sum(n))
IMPASD_freq <- IMPASD_freq %>%
inner_join(get_sentiments(sent_input), by = c(word = "word"))
IMPASD_freq <- IMPASD_freq %>% count (id, word, sort = TRUE)
total_words <- IMPASD_freq %>%
group_by(id) %>%
summarize(total = sum(n))
doc_words <- left_join(IMPASD_freq, total_words)
freq_by_rank <- doc_words %>%
group_by(id) %>%
mutate(rank = row_number(), termfrequency = n/total) %>%
ungroup()
doc_tf_idf <- doc_words %>%
bind_tf_idf(word, id, n)
doc_tf_idf %>%
select(-total) %>%
arrange(desc(tf_idf))
if (plotTF == TRUE)
{
ggplot(doc_words, aes(n/total, fill = id)) +
geom_histogram(show.legend = FALSE) +
xlim(NA, 0.0009) +
facet_wrap(~id, ncol = 2, scales = "free_y")
}
Sent_tf <- doc_tf_idf %>%
inner_join(get_sentiments(sent_input), by = c(word = "word"))
possent <- Sent_tf %>% filter(sentiment=="positive")
negsent <- Sent_tf %>% filter(sentiment=="negative")
Sent_tf <- bind_rows(possent, negsent)
#Sent_tf <- Sent_tf %>% semi_join(sent)
#return(Sent_tf)
if (plotTFidf == TRUE)
{
Sent_tf %>%
group_by(id) %>%
slice_max(tf_idf, n= 10) %>%
ungroup() %>%
ggplot(aes(tf_idf, reorder(word, tf_idf), fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(~id, ncol = 4, scales = "free", shrink = FALSE) +
labs(x = "tf-idf", y = NULL)
}
else{
addcounts <- create_tf_ratios(Sent_tf)
addcounts <- left_join(addcounts, words, by = "id")
return(addcounts)
}
}
#
visualize_sentiment <- function(tidy_text, sent_input, numwords){
tidy_text_plot <- tidy_text %>%
group_by(id) %>%
count(word, sort = TRUE) #creates a new tibble for plotting
IMP_all <- tidy_text_plot %>%
inner_join(get_sentiments(sent_input), by = c(word = "word"))
plot <- IMP_all %>% filter(as.integer(id)==1) %>%
count(sentiment, word, wt = n) %>%
ungroup() %>%
filter(n >= numwords) %>%
mutate(n = ifelse(sentiment == "negative", -n, n)) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word, fill = sentiment)) +
geom_col() +
labs(x = "Contribution to sentiment", y = NULL)
sent_count <- IMP_all %>% filter(as.integer(id)==1) %>%
count(sentiment, word, wt = n) %>%
ungroup()
print(plot)
print(sent_count)
}
#
sentiment_counts <- function(tidy_text, sent_input, sent){
tidy_text_plot <- tidy_text %>%
group_by(id) %>%
count(word, sort = TRUE) #creates a new tibble for plotting
IMP_all <- tidy_text_plot %>%
inner_join(get_sentiments(sent_input), by = c(word = "word"))
#plot <- IMP_all %>% filter(as.integer(id)==1) %>%
#count(sentiment, word, wt = n) %>%
#ungroup()
IMP_all <- IMP_all %>% filter(sentiment==sent) %>% summarize(Psum = sum(n))
return(IMP_all)
}
#
create_ratios <- function(tidy_text, sent_input) {
tidy_text_plot <- tidy_text %>%
group_by(id) %>%
count(word, sort = TRUE) #creates a new tibble for plotting
count <- tidy_text_plot %>% group_by(id) %>% summarize(wordcount = sum(n))
IMP_all <- tidy_text_plot %>%
inner_join(get_sentiments(sent_input), by = c(word = "word"))
possent <- IMP_all %>% filter(sentiment=="positive") %>% summarize(Psum = sum(n))
negsent <- IMP_all %>% filter(sentiment=="negative") %>% summarize(Nsum = sum(n))
sent <- left_join(possent, negsent, by = "id")
counts <- full_join(sent, count, by = "id")
final <- counts %>% mutate(Pratio = Psum/wordcount)
final2 <- final %>% mutate(Nratio = Nsum/wordcount)
final3 <- final2 %>% mutate(PNratio = (Psum-Nsum)/(Psum+Nsum))
return(final3)
}
#
create_tf_ratios <- function(IMP_all, sent_input) {
possent <- IMP_all %>% group_by(id) %>% filter(sentiment=="positive") %>% summarize(Psum = sum(n))
negsent <- IMP_all %>% group_by(id) %>% filter(sentiment=="negative") %>% summarize(Nsum = sum(n))
posidtdf <- IMP_all %>% group_by(id) %>% filter(sentiment=="positive") %>% summarize(Pitf = mean(tf_idf))
negidtdf <- IMP_all %>% group_by(id) %>% filter(sentiment=="negative") %>% summarize(Nitf = mean(tf_idf))
negidtdf
sent <- left_join(possent, negsent, by = "id")
sent <- left_join(sent, posidtdf, by = "id")
sent <- left_join(sent, negidtdf, by = "id")
sent <- sent %>% mutate(total = Psum+Nsum)
final <- sent %>% mutate(Pratio = Psum/total)
final2 <- final %>% mutate(Nratio = Nsum/total)
final3 <- final2 %>% mutate(PNratio = (Psum-Nsum)/total)
return(final3)
}
#
export <- function(tidy, name){
tidy <- data.frame(tidy)
write.csv(tidy, "C:\\Users\\jgronemeyer\\Documents\\R\\INS Abstract\\Exports\\"  name  ".csv")
export <- function(tidy, name){
tidy <- data.frame(tidy)
write.csv(tidy, "C:\\Users\\jgronemeyer\\Documents\\R\\INS Abstract\\Exports\\" + name + ".csv")
}
RAtdf <- tokenize_it(RAtidy)
RAtdf <- rem_stopwords(RAtdf)
tf_analysis(RAtidy, "bing", FALSE, TRUE)
tf_analysis(RAtidy, "bing", FALSE, TRUE)
tf_analysis <- function(file_corpus, sent_input, plotTF, plotTFidf){
IMPASD_freq <- file_corpus %>% mutate(id = factor(id)) %>%
unnest_tokens(word, text)
IMPASD_freq <- rem_stopwords(IMPASD_freq)
words <- IMPASD_freq %>% count (id, word, sort = TRUE) %>% group_by(id) %>% summarise(wordcount = sum(n))
IMPASD_freq <- IMPASD_freq %>%
inner_join(get_sentiments(sent_input), by = c(word = "word"))
IMPASD_freq <- IMPASD_freq %>% count (id, word, sort = TRUE)
total_words <- IMPASD_freq %>%
group_by(id) %>%
summarize(total = sum(n))
doc_words <- left_join(IMPASD_freq, total_words)
freq_by_rank <- doc_words %>%
group_by(id) %>%
mutate(rank = row_number(), termfrequency = n/total) %>%
ungroup()
doc_tf_idf <- doc_words %>%
bind_tf_idf(word, id, n)
doc_tf_idf %>%
select(-total) %>%
arrange(desc(tf_idf))
if (plotTF == TRUE)
{
ggplot(doc_words, aes(n/total, fill = id)) +
geom_histogram(show.legend = FALSE) +
xlim(NA, 0.0009) +
facet_wrap(~id, ncol = 2, scales = "free_y")
}
Sent_tf <- doc_tf_idf %>%
inner_join(get_sentiments(sent_input), by = c(word = "word"))
possent <- Sent_tf %>% filter(sentiment=="positive")
negsent <- Sent_tf %>% filter(sentiment=="negative")
Sent_tf <- bind_rows(possent, negsent)
#Sent_tf <- Sent_tf %>% semi_join(sent)
#return(Sent_tf)
if (plotTFidf == TRUE)
{
Sent_tf %>%
group_by(id) %>%
slice_max(tf_idf, n= 10) %>%
ungroup() %>%
ggplot(aes(tf_idf, reorder(word, tf_idf), fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(~id, ncol = 4, scales = "free", shrink = FALSE) +
labs(x = "tf-idf", y = NULL)
}
else{
addcounts <- create_tf_ratios(Sent_tf)
addcounts <- left_join(addcounts, words, by = "id")
return(addcounts)
}
}
tf_analysis(RAtidy, "bing", FALSE, TRUE)
rem_stopwords <- function(x) {
data("stop_words") #calls stop_word data set into Global Environment
tidy_text <- x %>%
anti_join(stop_words) #removes stop_words found in tidy_text
#mystopwords <- tibble(word = c("pop", "forget", "library", "skip", "spelling", "technology", "clerical", "unintelligible", "inaudible", "fully", "pay", "money", "swim", "splitting", "mother", "illegal", "stealing", "feeling", "police", "words", "question", "name1", "name2", "uhm", "um", "uh", "00", "etc", "let's", "gotta", "adrian", "bn"))
#mystopwords <- tibble(word = c("bug", "bugs" ,"pop", "forget", "library", "skip", "spelling", "technology", "clerical", "unintelligible", "inaudible", "fully", "pay", "money", "swim", "splitting", "mother", "illegal", "stealing", "feeling", "police", "words", "question", "name1", "name2", "uhm", "um", "uh", "00", "etc", "let's", "gotta", "adrian", "bn"))
tidy_text <- x %>%
anti_join(mystopwords) #removes stop_words found in tidy_text
return(tidy_text)
}
tf_analysis(RAtidy, "bing", FALSE, TRUE)
rem_stopwords <- function(x, mystopwords, customRemove) {
data("stop_words") #calls stop_word data set into Global Environment
tidy_text <- x %>%
anti_join(stop_words) #removes stop_words found in tidy_text
if (customRemove == TRUE)
{
tidy_text <- x %>%
anti_join(mystopwords)
}
#mystopwords <- tibble(word = c("pop", "forget", "library", "skip", "spelling", "technology", "clerical", "unintelligible", "inaudible", "fully", "pay", "money", "swim", "splitting", "mother", "illegal", "stealing", "feeling", "police", "words", "question", "name1", "name2", "uhm", "um", "uh", "00", "etc", "let's", "gotta", "adrian", "bn"))
#mystopwords <- tibble(word = c("bug", "bugs" ,"pop", "forget", "library", "skip", "spelling", "technology", "clerical", "unintelligible", "inaudible", "fully", "pay", "money", "swim", "splitting", "mother", "illegal", "stealing", "feeling", "police", "words", "question", "name1", "name2", "uhm", "um", "uh", "00", "etc", "let's", "gotta", "adrian", "bn"))
return(tidy_text)
}
RAtdf <- rem_stopwords(RAtdf, FALSE)
rem_stopwords <- function(x, customRemove, mystopwords) {
if (customRemove == TRUE)
{
data("stop_words") #calls stop_word data set into Global Environment
tidy_text <- x %>%
anti_join(stop_words) #removes stop_words found in tidy_text
tidy_text <- x %>%
anti_join(mystopwords)
return(tidy_text)
}
#mystopwords <- tibble(word = c("pop", "forget", "library", "skip", "spelling", "technology", "clerical", "unintelligible", "inaudible", "fully", "pay", "money", "swim", "splitting", "mother", "illegal", "stealing", "feeling", "police", "words", "question", "name1", "name2", "uhm", "um", "uh", "00", "etc", "let's", "gotta", "adrian", "bn"))
#mystopwords <- tibble(word = c("bug", "bugs" ,"pop", "forget", "library", "skip", "spelling", "technology", "clerical", "unintelligible", "inaudible", "fully", "pay", "money", "swim", "splitting", "mother", "illegal", "stealing", "feeling", "police", "words", "question", "name1", "name2", "uhm", "um", "uh", "00", "etc", "let's", "gotta", "adrian", "bn"))
else (customRemove == FALSE)
{
data("stop_words") #calls stop_word data set into Global Environment
tidy_text <- x %>%
anti_join(stop_words) #removes stop_words found in tidy_text
return(tidy_text)
}
}
tf_analysis(RAtidy, "bing", FALSE, TRUE)
rem_stopwords <- function(x, customRemove, mystopwords) {
if (customRemove == TRUE)
{
data("stop_words") #calls stop_word data set into Global Environment
tidy_text <- x %>%
anti_join(stop_words) #removes stop_words found in tidy_text
tidy_text <- x %>%
anti_join(mystopwords)
return(tidy_text)
}
#mystopwords <- tibble(word = c("pop", "forget", "library", "skip", "spelling", "technology", "clerical", "unintelligible", "inaudible", "fully", "pay", "money", "swim", "splitting", "mother", "illegal", "stealing", "feeling", "police", "words", "question", "name1", "name2", "uhm", "um", "uh", "00", "etc", "let's", "gotta", "adrian", "bn"))
#mystopwords <- tibble(word = c("bug", "bugs" ,"pop", "forget", "library", "skip", "spelling", "technology", "clerical", "unintelligible", "inaudible", "fully", "pay", "money", "swim", "splitting", "mother", "illegal", "stealing", "feeling", "police", "words", "question", "name1", "name2", "uhm", "um", "uh", "00", "etc", "let's", "gotta", "adrian", "bn"))
else
{
data("stop_words") #calls stop_word data set into Global Environment
tidy_text <- x %>%
anti_join(stop_words) #removes stop_words found in tidy_text
return(tidy_text)
}
}
RA_tf <- tf_analysis(RAtidy, "nrc", FALSE, FALSE)
#
tf_analysis <- function(file_corpus, sent_input, plotTF, plotTFidf){
get_Total <- file_corpus %>% mutate(id = factor(id)) %>%
unnest_tokens(word, text)
get_Total <- rem_stopwords(get_Total, FALSE)
words <- get_Total %>% count (id, word, sort = TRUE) %>% group_by(id) %>% summarise(wordcount = sum(n))
get_Total <- get_Total %>%
inner_join(get_sentiments(sent_input), by = c(word = "word"))
get_Total <- get_Total %>% count (id, word, sort = TRUE)
total_words <- get_Total %>%
group_by(id) %>%
summarize(total = sum(n))
doc_words <- left_join(get_Total, total_words)
freq_by_rank <- doc_words %>%
group_by(id) %>%
mutate(rank = row_number(), termfrequency = n/total) %>%
ungroup()
doc_tf_idf <- doc_words %>%
bind_tf_idf(word, id, n)
doc_tf_idf %>%
select(-total) %>%
arrange(desc(tf_idf))
if (plotTF == TRUE)
{
ggplot(doc_words, aes(n/total, fill = id)) +
geom_histogram(show.legend = FALSE) +
xlim(NA, 0.0009) +
facet_wrap(~id, ncol = 2, scales = "free_y")
}
Sent_tf <- doc_tf_idf %>%
inner_join(get_sentiments(sent_input), by = c(word = "word"))
possent <- Sent_tf %>% filter(sentiment=="positive")
negsent <- Sent_tf %>% filter(sentiment=="negative")
Sent_tf <- bind_rows(possent, negsent)
#Sent_tf <- Sent_tf %>% semi_join(sent)
#return(Sent_tf)
if (plotTFidf == TRUE)
{
Sent_tf %>%
group_by(id) %>%
slice_max(tf_idf, n= 10) %>%
ungroup() %>%
ggplot(aes(tf_idf, reorder(word, tf_idf), fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(~id, ncol = 4, scales = "free", shrink = FALSE) +
labs(x = "tf-idf", y = NULL)
}
else
{
addcounts <- create_tf_ratios(Sent_tf)
addcounts <- left_join(addcounts, words, by = "id")
return(addcounts)
}
}
tf_analysis(RAtidy, "bing", FALSE, TRUE)
tf_analysis(RAtidy, "bing", TRUE, FALSE)
RA_tf <- tf_analysis(RAtidy, "bing", FALSE, FALSE)
View(RA_tf)
RAcounts <- create_tf_ratios(RA_tf, "bing")
RA_tf <- tf_analysis(RAtidy, "bing", FALSE, FALSE)
RAcounts <- create_tf_ratios(RA_tf, "bing")
View(RA_tf)
RAcounts <- create_tf_ratios(RAtdf, "bing")
install.packages("textdata")
install.packages("SentimentAnalysis")
install.packages("textdata")
install.packages("SentimentAnalysis")
install.packages("SentimentAnalysis")
RAcounts <- create_tf_ratios(RAtdf, "bing")
library (dplyr)
visualize_sentiment(RAtdf, "bing", 2)
library (SentimentAnalysis)
library (tidytext)
visualize_sentiment(RAtdf, "bing", 2)
library (tm)
library (tidyr)
library (readr)
library (stringi)
library (RWeka)
library (ggplot2)
library (wordcloud)
library (SnowballC)
library (gridExtra)
library (textmineR)
library (tidytext)
library (SentimentAnalysis)
library (dplyr)
library (stringr)
library (tidytext)
library (qdap)
library (textdata)
library (igraph)
library (ggraph)
visualize_sentiment(RAtdf, "bing", 2)
FUbigrams <- bigram_it(FUtidy)
RAbigrams <- bigram_it(RAtidy)
bigram_it <- function(file_corpus, tidyIDs = FALSE) {
#this function requires a tidy file corpus as input
if (tidyIDs == TRUE)
{
cnt <- 1 #tidy up the id names
repeat{
file_corpus[["id"]][[cnt]] <- substr(file_corpus[["id"]][[cnt]], 1, 12) #substracts all parts of the char string and leaves 1-10
cnt <- cnt+1
if(cnt > length(file_corpus)){
break
}
}
}
tidy_corp <- file_corpus %>%
group_by(id) %>%
summarize(text) %>%
mutate(id = factor(id)) %>% #make sure to mutate the "id" column^
ungroup() #formats corpus for tidy analysis
tidy_text <- tidy_corp %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) #creates tidy text tibble
bigrams_seperated <- tidy_text %>%
separate(bigram, c("word1", "word2"), sep = " ")
bigrams_filtered <- bigrams_seperated %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
mystopwords <- tibble(word = c("name 1", "name 2", "uhm", "um", "uh", "00", "etc", "let's", "gotta", "adrian", "bn"))
bigrams_filtered <- bigrams_filtered %>%
filter(!word1 %in% mystopwords$word) %>%
filter(!word2 %in% mystopwords$word)
bigram_counts <- bigrams_filtered %>%
count(word1, word2, sort = TRUE)
file_corpus <- tidy_text
return(bigram_counts)
}
RAbigrams <- bigram_it(RAtidy)
bigram_network(RAbigrams)
bigram_network <- function (bigram_counts){
#requires library("igraph") and ggraph
bigram_graph <- bigram_counts %>%
filter(n > 1) %>%
graph_from_data_frame()
ggraph(bigram_graph, layout = "fr") +
geom_edge_link() +
geom_node_point() +
geom_node_text(aes(label = name), vjust = 1, hjust = 1)
}
bigram_network(RAbigrams)
tf_analysis(RAtidy, "bing", FALSE, TRUE)
tf_analysis(RAtidy, "bing", TRUE, FALSE)
RAcounts_tdf <- create_tf_ratios(RAtdf, "bing")
RAcounts <- create_ratios(RAtdf, "bing")
visualize_sentiment(RAtdf, "bing", 2)
